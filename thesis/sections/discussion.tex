\chapter{Discussion}
\label{ch:discussion}

This chapter discusses the findings of the developed hybrid analyticalâ€“machine learning framework, examining the behavior of the analytical model, the effect of preference-weighted scoring, the integration of synthetic data with machine learning, and overall system-level considerations and limitations.

% ---------------------------------------------------------------------------
\section{Analytical Model Behavior and Validity}
\label{sec:analytical_behavior}

The hybrid approach ensured that no mechanically unfit solution is ever recommended, because the analytical feasibility check acts as a gatekeeper. This represents a significant advantage over purely data-driven approaches. In examining the analytical model's behavior, it was found to be consistent with standard engineering knowledge~\cite{DIN7190_2017,DIN6885_2021,DIN5480_2006}. The inclusion of the interference plausibility filter for press fits proved important: it prevented the model from favoring press fits in scenarios where the required interference was unrealistically high (e.g., small-diameter shafts requiring high torque). In those cases, the system correctly defaulted to recommending splines (or keys), which is what a human expert would also do, knowing that extreme press fits are not practical. This behavior aligns with practical design rules where press fits are often limited by assembly constraints rather than static torque capacity alone~\cite{FVA_InterferenceFits_2017}.

For keyed joints, the results show that the bearing pressure limit often governs the design rather than shear strength, especially for larger shafts or softer hub materials. This matches textbook knowledge: keys tend to crush the keyway walls before the key shears if designed per standards~\cite{DIN6885_2021}. The system captured this by computing both limits and using the smaller---effectively, the key is designed to the bearing stress in many cases. It was also noted that the analytical model would avoid recommending a single key for very high torques; beyond a certain point, it simply marks the key option infeasible. An experienced designer might in reality consider using multiple keys indexed around the shaft or a keyed connection of larger dimensions than standard---those are outside the current scope, but the system can be extended to consider multiple keys as a separate option in future work.

Splined connections in the results showed very high torque capacity across a wide range of sizes, as expected due to load sharing~\cite{DIN5480_2006}. Interestingly, the system did not always select the spline even if it had far more capacity---which is by design, as the goal was not to always choose the ``strongest'' connection irrespective of other factors. Only when preferences or feasibility dictated did spline become the top choice. The notion that ``the strongest is not always the best if not needed'' was effectively encoded by penalizing overdesign. In scenarios with neutral preferences, the analytical scorer tended to choose the press fit or key up until they were near their limits, and only then switch to spline. This reflects a reasonable engineering economy principle. If anything, it might even underweight splines in borderline cases, but that is where user preferences (such as durability) could tip the scale to spline if the user desires a larger safety margin.

One limitation observed is that the analytical model uses somewhat simplified assumptions (e.g., a single value for friction coefficient or for allowable stress taken as a fixed fraction of yield strength). In reality, factors such as stress concentrations for keys can reduce fatigue life more significantly than the static model indicates, or fretting in press fits can occur under cyclic load even if static slip safety is satisfied. These aspects are not fully captured, meaning the tool's analytical side is conservative within its scope but cannot replace a detailed analysis for final design. Nonetheless, within the scope of static, single-load-case comparison, the analytical module's behavior is sound.

% ---------------------------------------------------------------------------
\section{Effect of Preference-Weighted Scoring}
\label{sec:preference_scoring}

The introduction of preference weighting proved to be a powerful feature. It allowed the system to differentiate between multiple feasible solutions in a rational and traceable manner. In scenarios where, for example, both a press fit and a spline were feasible, the one that aligned better with the user's priorities was recommended. This is an improvement over a purely deterministic approach that might always select, for example, the press fit because it is simpler, even if the use case would benefit from a spline's advantages. The preference mechanism essentially provides a quantitative voice to non-strength criteria. Feedback from users indicated this made the tool feel more context-aware. For instance, when a user emphasized ``maintenance ease,'' they observed the system favor keys even in some cases where keys were slightly less robust than a press fit, which matches the user's intent (preferring something that can be taken apart easily for maintenance). If all preferences were set to zero (or equal), the system defaults to a purely mechanics-based choice (or might default to whichever has slight inherent scoring advantages such as cost). This ability to smoothly transition between objective mechanical facts and subjective priorities is a notable benefit of the hybrid approach.

One observation is that if a user sets contradictory preferences (e.g., maximum on both low cost and high durability), the system currently weights them equally and sums---which might lead to a balanced decision or an unclear one. In reality, an experienced engineer might realize that those criteria trade off and make a more nuanced choice. The linear weighted sum approach is a first-order method. It worked well in tests to differentiate options, but it could be further refined (perhaps using a more advanced multi-criteria decision-making method or even learning typical preference trade-off behaviors from experts). Still, the current implementation showed that the same design input can lead to different recommended connections under different priorities, which is valuable. It demonstrates that the system is not just learning a one-size-fits-all rule (``always use spline above X torque'') but truly factoring in the scenario context.

The scoring mechanism also had built-in penalties for scenarios such as press fits in thin hubs or overly high safety factors for cost-sensitive cases. These acted as intended---for example, even if a user had no particular preference, the system would down-rank a press fit if the hub was very thin (preferring a key or spline that puts less stress on the hub). This kind of nuance would be difficult to capture in a pure ML model without explicit data; the hybrid approach handles it transparently.

% ---------------------------------------------------------------------------
\section{Synthetic Data and ML Model Integration}
\label{sec:synthetic_data_integration}

Using synthetic data generated from analytical rules turned out to be a successful strategy for training the ML model~\cite{Picard_2023}. One might question whether the ML model would simply mirror the analytical model (which is by design for the core decision logic), raising the question: what advantage does the ML model provide if analytical formulas already exist? The answer found is that the ML model, once trained, serves as a fast surrogate and also as a way to generalize the decision in a smoother manner. The boundaries learned by the ML model can effectively interpolate between cases. For instance, if the analytical rules had a sharp cutoff at a certain torque for a key, the ML might learn a probabilistic transition (giving, say, 0.4 probability to key and 0.6 to spline around that point) rather than an abrupt switch. This is useful when presenting to a user---it naturally expresses confidence levels that match how an expert might say ``you are on the fence between a key and a spline here.'' Such nuance is harder to program into a strict rule-based system but emerges naturally from the ML model's probabilistic nature~\cite{Breiman_2001}. In the web application results, cases were indeed observed where the ML gave, for example, an 80\% versus 20\% split, communicating a softer decision. The deterministic analytical logic would have to arbitrarily pick one in those cases, potentially without indicating closeness.

From a performance standpoint, the ML model integration makes the system scalable. If one wanted to embed this selection capability into an optimization loop (e.g., optimizing a gearbox design, evaluating different shaft sizes and connection types automatically), the ML model can provide near-instant decisions without invoking heavy calculations repeatedly. The analytical calculations are not heavy individually, but as complexity grows (imagine extending to more connection types or more detailed stress checks), an ML surrogate becomes attractive.

It is important to acknowledge that the ML model's validity is tied to the synthetic data quality. The model was essentially taught the same biases and limitations as the analytical generator. For example, since polygon shaft profiles or clamping connections were not included in the dataset, the model will not consider those---it does not know they exist. If a query outside the original parameter range is given (extrapolation), the model might be less accurate. This was partially mitigated by choosing a broad range for training. In practice, the integration of the ML with the analytical backend means the analytical check always serves as a safety net---the analytical module's feasibility check is used even when presenting ML results. This way, if the ML ever suggested an infeasible option (which it theoretically should not if trained perfectly, but as a precaution), the system would catch it. In testing, no such contradiction was observed; the ML's outputs always corresponded to feasible options. This redundancy adds trustworthiness.

% ---------------------------------------------------------------------------
\section{System-Level Considerations and Limitations}
\label{sec:limitations}

The combined system---analytical plus ML plus user interface---demonstrates a pathway for AI-assisted engineering design. One of the key outcomes is showing that machine learning can be harnessed without experimental data by using established knowledge to generate synthetic data. This effectively bridges deterministic design formulas with stochastic prediction. A benefit of having both components is interpretability: the user sees not only what the ML predicts, but why, because the underlying physics are exposed (torque margins, etc.). This helps address the common reluctance to trust AI in critical engineering decisions---the user is not asked to trust a black box, but an interpretable hybrid system that still shows familiar engineering quantities.

In terms of limitations, one is that the model currently assumes a static load and a single operating condition. In real applications, factors such as fatigue under variable loads, shock loads, misalignment, and environmental influences (corrosion, temperature) could affect the choice of connection. For example, keys under reversing loads can loosen (backlash development), splines under misalignment can concentrate load on a few teeth, and press fits at high temperature may lose interference. These factors are not explicitly modeled. Some are partially accounted for via user preferences (e.g., a user concerned about vibration or reversing loads will likely increase the durability or bidirectional-load preference, indirectly favoring splines), but the quantitative effects are not in the analytical formulas. Future work could integrate these (perhaps by extending the analytical model or adding more inputs such as a ``dynamic load factor''). Another limitation is that the material library is limited to a few common steels, cast iron, aluminum, etc., and a single friction coefficient distribution is used for all steels in ``dry'' versus ``oiled'' state. In reality, different surface finishes or coatings can drastically change friction~\cite{GWJ_eAssistant_DIN7190}. The tool allows the user to override the friction coefficient manually if known, but the ML model does not take that override into account (the override is handled analytically after prediction). Thus, the ML might mispredict if a very unusual friction value is used. Retraining with such cases or expanding the feature set could address this if needed.

From a deployment perspective, the FastAPI/React setup worked well and illustrates that such engineering tools can be made accessible via web technology for broader use. One must consider the target user: a trained mechanical engineer might want more control or might distrust an AI suggestion, whereas a novice might overly trust it. An attempt was made to balance this by providing information and not automating away the reasoning. The tool is thus well-suited for educational use or preliminary design---it can quickly show a student how different factors play into a design choice, or help an engineer perform a first-pass selection when sizing a machine. However, it is recommended that for final decisions, the results be reviewed by an expert or further verified with detailed analysis (finite element analysis for stress, etc.), especially for critical applications. This is in line with the positioning of the system as a decision-support tool, not a replacement for detailed engineering design processes~\cite{Haggenmueller_2025}.

Finally, a broader implication of this work is the demonstrated feasibility of encoding engineering standards into a format that AI can learn. Parts of DIN~7190, 6885, and 5480 were effectively translated into a dataset and then into a model~\cite{DIN7190_2017,DIN6885_2021,DIN5480_2006}. This approach could be extended to other design standards and tasks, suggesting a future where an engineer might have a suite of AI assistants for different design decisions---all grounded by the domain knowledge of standards.
